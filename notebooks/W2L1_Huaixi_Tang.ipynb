{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will\n",
    "- read our project data into a Pandas DataFrame\n",
    "- write a function to compute simple features for each row of the data frame\n",
    "- fit a LogisticRegression model to the data\n",
    "- print the top coefficients\n",
    "- compute measures of accuracy\n",
    "\n",
    "I've given you starter code below. You should:\n",
    "- First, try to get it to work with your data. It may require changing the load_data file to match the requirements of your data (e.g., what is the object you are classifying -- a tweet, a user, a news article?)\n",
    "- Second, you should add additional features to the make_features function:\n",
    "  - Be creative. It could be additional word features, or other meta data about the user, date, etc.\n",
    "- As you try out different feature combinations, print out the coefficients and accuracy scores\n",
    "- List any features that seem to improve accuracy. Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter</td>\n",
       "      <td>920307162278236160</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @allisonpohle : o-h-i-no ! this story wasn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter</td>\n",
       "      <td>920464477388029952</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @theellenshow : tomorrow , the first people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter</td>\n",
       "      <td>918272604410122240</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @lauraloomer : investigative journalist lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter</td>\n",
       "      <td>918689132137791488</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @lauraloomer : #jesuscampos be miss ? laura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter</td>\n",
       "      <td>913244272643653632</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @tacticalpoet84 : urlref\\nfollow-up from my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>twitter</td>\n",
       "      <td>911837232633323520</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @tacticalpoet84 : find out my video mean fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>twitter</td>\n",
       "      <td>911652673002266624</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @jjmacnab : militia extremist be be agitate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twitter</td>\n",
       "      <td>917083461197946880</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @jasonlacanfora : report about @kaepernick7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>twitter</td>\n",
       "      <td>917083461197946880</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @jasonlacanfora : report about @kaepernick7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>twitter</td>\n",
       "      <td>917082971030552576</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @jasonlacanfora : stand for anthem wasn't s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>twitter</td>\n",
       "      <td>917082971030552576</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @jasonlacanfora : stand for anthem wasn't s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>twitter</td>\n",
       "      <td>917084351560671232</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @jasonlacanfora : i know @kaepernick7 be fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>twitter</td>\n",
       "      <td>924968401470070784</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @foxandfriends : . @jonathanturley : #muell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>twitter</td>\n",
       "      <td>924973670841192448</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @foxandfriends : fox news alert : report sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>twitter</td>\n",
       "      <td>794373705031790592</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @m_ojigichan : 【 衝撃映像 】 こんな対戦相手は嫌だ 【 卓球少女 】...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>twitter</td>\n",
       "      <td>920611770775064576</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @realdonaldtrump : democrat congresswoman t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>twitter</td>\n",
       "      <td>922440008971292672</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @realdonaldtrump : i have a very respectful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>twitter</td>\n",
       "      <td>922728410891333632</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @deerparkcbs : lot of preparation for fearp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>twitter</td>\n",
       "      <td>723604111330033664</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @deerparkcbs : first year student busy make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>twitter</td>\n",
       "      <td>922881681962434560</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @oldpicsarchive : jimi urlref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>twitter</td>\n",
       "      <td>923832152713826304</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @deerparkcbs : student be ask to be on thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>twitter</td>\n",
       "      <td>917419435270508544</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @newsweek : exclusive : judi dench , who ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>twitter</td>\n",
       "      <td>911904261553950720</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @realdonaldtrump : if nfl fan refuse to go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>twitter</td>\n",
       "      <td>911904261553950720</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @realdonaldtrump : if nfl fan refuse to go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>twitter</td>\n",
       "      <td>803567993036754944</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @realdonaldtrump : nobody should be allow t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>twitter</td>\n",
       "      <td>42341540923838464</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @realdonaldtrump : check out today's video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>twitter</td>\n",
       "      <td>42278544969179136</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @realdonaldtrump : also come up : the celeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>twitter</td>\n",
       "      <td>909944471357464576</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @ncstories : wave from hurricane jose today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>twitter</td>\n",
       "      <td>908455229452103680</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @satanicpsalms : despite some report @ppact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>twitter</td>\n",
       "      <td>908455229452103680</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>rt @satanicpsalms : despite some report @ppact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>twitter</td>\n",
       "      <td>887393171923185664</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @comedycentral : break news . urlref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>twitter</td>\n",
       "      <td>711379246506115072</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @jcrillz : these little guy may look like s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>twitter</td>\n",
       "      <td>816727208538542080</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @cnnpolitics : mcconnell : \" the american p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>twitter</td>\n",
       "      <td>843362397666664448</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @lifesbook_ceo : be i the only person wonde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>twitter</td>\n",
       "      <td>844216511996690432</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @markfiore : roger stone , very proud of hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>twitter</td>\n",
       "      <td>845827254953295872</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @pslweb : actually , in that particular iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>twitter</td>\n",
       "      <td>845376880056418304</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @thedemocrats : the gop pull their disastro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>twitter</td>\n",
       "      <td>472413469669875712</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @melaniatrump : #fbf 2006 @annieleibovitz f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>twitter</td>\n",
       "      <td>785298143139233792</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @thebriefing2016 : think the bush tax cut d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>twitter</td>\n",
       "      <td>667707402112917504</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @simon_schama : oed definition of trumpery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>twitter</td>\n",
       "      <td>739076562876829696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @realdonaldtrump : \" @don_vito_08 : thank y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>twitter</td>\n",
       "      <td>739083074177257472</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @markczerniec : seriously shameful : trump'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>twitter</td>\n",
       "      <td>710647812434755584</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @hnstyngov : i don't think melania #trump p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>twitter</td>\n",
       "      <td>849637931543298048</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @fyrefraud : isn't it strange there be no s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>twitter</td>\n",
       "      <td>847100891446595584</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @fyrefraud : how do you transport and store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>twitter</td>\n",
       "      <td>857914539248975872</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @jananbuisier : #exumaairport official just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>twitter</td>\n",
       "      <td>857949787513139200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @visitthebahamas : bahamas official stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>twitter</td>\n",
       "      <td>857879108189138944</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @iron_spike : the \" cater \" ( which cost ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>twitter</td>\n",
       "      <td>857878583515197440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @iron_spike : the \" luxury \" glamping tent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>twitter</td>\n",
       "      <td>857752766940426240</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @wnfiv : night ha fall . we have no luggage .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>twitter</td>\n",
       "      <td>857744138019753984</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @wnfiv : so fyre fest be a complete disaste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>twitter</td>\n",
       "      <td>859577178266226688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @andyostroy : seem the only #wall @realdona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>twitter</td>\n",
       "      <td>725387829291802624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @hrc : #callitout : oxford alabama city cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>twitter</td>\n",
       "      <td>857726539835854848</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @michelesmi : @fyrefraud just a reminder of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>twitter</td>\n",
       "      <td>857726539835854848</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@mrwankstein ' s account be temporarily unavai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>twitter</td>\n",
       "      <td>858025172942675968</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @ruleyork : urlref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>twitter</td>\n",
       "      <td>793831493986492416</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @foxnews : . @realdonaldtrump : \" wisconsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>twitter</td>\n",
       "      <td>732357465812144128</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @cnn : yellowstone bison calf euthanized af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>twitter</td>\n",
       "      <td>827867311054974976</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @realdonaldtrump : the opinion of this so-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>twitter</td>\n",
       "      <td>210887102865473536</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rt @mayorsamadams : clarification : only 18 % ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1257 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         site                  id  label  \\\n",
       "0     twitter  920307162278236160   -2.0   \n",
       "1     twitter  920464477388029952   -2.0   \n",
       "2     twitter  918272604410122240   -2.0   \n",
       "3     twitter  918689132137791488   -2.0   \n",
       "4     twitter  913244272643653632   -2.0   \n",
       "5     twitter  911837232633323520   -2.0   \n",
       "6     twitter  911652673002266624   -2.0   \n",
       "7     twitter  917083461197946880   -2.0   \n",
       "8     twitter  917083461197946880   -2.0   \n",
       "9     twitter  917082971030552576   -2.0   \n",
       "10    twitter  917082971030552576   -2.0   \n",
       "11    twitter  917084351560671232   -2.0   \n",
       "12    twitter  924968401470070784   -2.0   \n",
       "13    twitter  924973670841192448   -2.0   \n",
       "14    twitter  794373705031790592   -2.0   \n",
       "15    twitter  920611770775064576   -2.0   \n",
       "16    twitter  922440008971292672   -2.0   \n",
       "17    twitter  922728410891333632   -2.0   \n",
       "18    twitter  723604111330033664   -2.0   \n",
       "19    twitter  922881681962434560   -2.0   \n",
       "20    twitter  923832152713826304   -2.0   \n",
       "21    twitter  917419435270508544   -2.0   \n",
       "22    twitter  911904261553950720   -2.0   \n",
       "23    twitter  911904261553950720   -2.0   \n",
       "24    twitter  803567993036754944   -2.0   \n",
       "25    twitter   42341540923838464   -2.0   \n",
       "26    twitter   42278544969179136   -2.0   \n",
       "27    twitter  909944471357464576   -2.0   \n",
       "28    twitter  908455229452103680   -2.0   \n",
       "29    twitter  908455229452103680   -2.0   \n",
       "...       ...                 ...    ...   \n",
       "1227  twitter  887393171923185664    2.0   \n",
       "1228  twitter  711379246506115072    2.0   \n",
       "1229  twitter  816727208538542080    2.0   \n",
       "1230  twitter  843362397666664448    2.0   \n",
       "1231  twitter  844216511996690432    2.0   \n",
       "1232  twitter  845827254953295872    2.0   \n",
       "1233  twitter  845376880056418304    2.0   \n",
       "1234  twitter  472413469669875712    2.0   \n",
       "1235  twitter  785298143139233792    2.0   \n",
       "1236  twitter  667707402112917504    2.0   \n",
       "1237  twitter  739076562876829696    2.0   \n",
       "1238  twitter  739083074177257472    2.0   \n",
       "1239  twitter  710647812434755584    2.0   \n",
       "1240  twitter  849637931543298048    2.0   \n",
       "1241  twitter  847100891446595584    2.0   \n",
       "1242  twitter  857914539248975872    2.0   \n",
       "1243  twitter  857949787513139200    2.0   \n",
       "1244  twitter  857879108189138944    2.0   \n",
       "1245  twitter  857878583515197440    2.0   \n",
       "1246  twitter  857752766940426240    2.0   \n",
       "1247  twitter  857744138019753984    2.0   \n",
       "1248  twitter  859577178266226688    2.0   \n",
       "1249  twitter  725387829291802624    2.0   \n",
       "1250  twitter  857726539835854848    2.0   \n",
       "1251  twitter  857726539835854848    2.0   \n",
       "1252  twitter  858025172942675968    2.0   \n",
       "1253  twitter  793831493986492416    2.0   \n",
       "1254  twitter  732357465812144128    2.0   \n",
       "1255  twitter  827867311054974976    2.0   \n",
       "1256  twitter  210887102865473536    2.0   \n",
       "\n",
       "                                                   text  \n",
       "0     rt @allisonpohle : o-h-i-no ! this story wasn'...  \n",
       "1     rt @theellenshow : tomorrow , the first people...  \n",
       "2     rt @lauraloomer : investigative journalist lau...  \n",
       "3     rt @lauraloomer : #jesuscampos be miss ? laura...  \n",
       "4     rt @tacticalpoet84 : urlref\\nfollow-up from my...  \n",
       "5     rt @tacticalpoet84 : find out my video mean fo...  \n",
       "6     rt @jjmacnab : militia extremist be be agitate...  \n",
       "7     rt @jasonlacanfora : report about @kaepernick7...  \n",
       "8     rt @jasonlacanfora : report about @kaepernick7...  \n",
       "9     rt @jasonlacanfora : stand for anthem wasn't s...  \n",
       "10    rt @jasonlacanfora : stand for anthem wasn't s...  \n",
       "11    rt @jasonlacanfora : i know @kaepernick7 be fu...  \n",
       "12    rt @foxandfriends : . @jonathanturley : #muell...  \n",
       "13    rt @foxandfriends : fox news alert : report sa...  \n",
       "14    rt @m_ojigichan : 【 衝撃映像 】 こんな対戦相手は嫌だ 【 卓球少女 】...  \n",
       "15    rt @realdonaldtrump : democrat congresswoman t...  \n",
       "16    rt @realdonaldtrump : i have a very respectful...  \n",
       "17    rt @deerparkcbs : lot of preparation for fearp...  \n",
       "18    rt @deerparkcbs : first year student busy make...  \n",
       "19                     rt @oldpicsarchive : jimi urlref  \n",
       "20    rt @deerparkcbs : student be ask to be on thei...  \n",
       "21    rt @newsweek : exclusive : judi dench , who ha...  \n",
       "22    rt @realdonaldtrump : if nfl fan refuse to go ...  \n",
       "23    rt @realdonaldtrump : if nfl fan refuse to go ...  \n",
       "24    rt @realdonaldtrump : nobody should be allow t...  \n",
       "25    rt @realdonaldtrump : check out today's video ...  \n",
       "26    rt @realdonaldtrump : also come up : the celeb...  \n",
       "27    rt @ncstories : wave from hurricane jose today...  \n",
       "28    rt @satanicpsalms : despite some report @ppact...  \n",
       "29    rt @satanicpsalms : despite some report @ppact...  \n",
       "...                                                 ...  \n",
       "1227            rt @comedycentral : break news . urlref  \n",
       "1228  rt @jcrillz : these little guy may look like s...  \n",
       "1229  rt @cnnpolitics : mcconnell : \" the american p...  \n",
       "1230  rt @lifesbook_ceo : be i the only person wonde...  \n",
       "1231  rt @markfiore : roger stone , very proud of hi...  \n",
       "1232  rt @pslweb : actually , in that particular iss...  \n",
       "1233  rt @thedemocrats : the gop pull their disastro...  \n",
       "1234  rt @melaniatrump : #fbf 2006 @annieleibovitz f...  \n",
       "1235  rt @thebriefing2016 : think the bush tax cut d...  \n",
       "1236  rt @simon_schama : oed definition of trumpery ...  \n",
       "1237  rt @realdonaldtrump : \" @don_vito_08 : thank y...  \n",
       "1238  rt @markczerniec : seriously shameful : trump'...  \n",
       "1239  rt @hnstyngov : i don't think melania #trump p...  \n",
       "1240  rt @fyrefraud : isn't it strange there be no s...  \n",
       "1241  rt @fyrefraud : how do you transport and store...  \n",
       "1242  rt @jananbuisier : #exumaairport official just...  \n",
       "1243  rt @visitthebahamas : bahamas official stateme...  \n",
       "1244  rt @iron_spike : the \" cater \" ( which cost ex...  \n",
       "1245  rt @iron_spike : the \" luxury \" glamping tent ...  \n",
       "1246   rt @wnfiv : night ha fall . we have no luggage .  \n",
       "1247  rt @wnfiv : so fyre fest be a complete disaste...  \n",
       "1248  rt @andyostroy : seem the only #wall @realdona...  \n",
       "1249  rt @hrc : #callitout : oxford alabama city cou...  \n",
       "1250  rt @michelesmi : @fyrefraud just a reminder of...  \n",
       "1251  @mrwankstein ' s account be temporarily unavai...  \n",
       "1252                              rt @ruleyork : urlref  \n",
       "1253  rt @foxnews : . @realdonaldtrump : \" wisconsin...  \n",
       "1254  rt @cnn : yellowstone bison calf euthanized af...  \n",
       "1255  rt @realdonaldtrump : the opinion of this so-c...  \n",
       "1256  rt @mayorsamadams : clarification : only 18 % ...  \n",
       "\n",
       "[1257 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(datafile, checkfile):\n",
    "    \"\"\"\n",
    "    Read your data into a single pandas dataframe where\n",
    "    - each row is an instance to be classified\n",
    "    \n",
    "    (this could be a tweet, user, or news article, depending on your project)\n",
    "    - there is a column called `label` which stores the class label (e.g., the true\n",
    "      category for this row)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(datafile)[['social_id','comment_tokens']]\n",
    "    ck = pd.read_csv(checkfile)\n",
    "    \n",
    "    ck = ck.loc[ck['site'] == 'twitter', ['site', 'social_id', 'ruling_val']]\n",
    "    \n",
    "    \n",
    "    ck['social_id'] = ck['social_id'].astype(df['social_id'].dtype)\n",
    "    \n",
    "    df.columns = ['id', 'text']\n",
    "    df = df.drop_duplicates(['id','text'])\n",
    "    ck.columns = ['site','id','label']\n",
    "   # ck['label'] = [i.lower() for i in ck.label]\n",
    "    df = pd.merge(ck,df,on=['id'],how = 'inner')\n",
    "    return df\n",
    "\n",
    "df = load_data('..\\\\..\\\\training_data\\\\twitter.csv.gz', '..\\\\..\\\\training_data\\\\factchecks.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0    650\n",
       " 0.0    201\n",
       "-1.0    176\n",
       " 2.0    141\n",
       " 1.0     89\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution over class labels?\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'the',\n",
       " 'urlref',\n",
       " 'be',\n",
       " 'to',\n",
       " 'a',\n",
       " 'in',\n",
       " 'of',\n",
       " 's',\n",
       " 'and',\n",
       " 'i',\n",
       " 'it',\n",
       " 'on',\n",
       " 'for',\n",
       " 'mention_realdonaldtrump',\n",
       " 'this',\n",
       " 'that',\n",
       " 't',\n",
       " 'have',\n",
       " 'we',\n",
       " 'trump',\n",
       " 'wa',\n",
       " 'with',\n",
       " 'you',\n",
       " 'at',\n",
       " 'not',\n",
       " 'he',\n",
       " 'do',\n",
       " 'ha',\n",
       " 'no',\n",
       " 'my',\n",
       " 'u',\n",
       " 'from',\n",
       " 'by',\n",
       " 'say',\n",
       " 'they',\n",
       " 'our',\n",
       " 'if',\n",
       " 'more',\n",
       " 'people',\n",
       " 'about',\n",
       " 'an',\n",
       " 'his',\n",
       " 'will',\n",
       " 'but',\n",
       " 'just',\n",
       " 'what',\n",
       " 'would',\n",
       " 'get',\n",
       " 'obama',\n",
       " 'go',\n",
       " 'all',\n",
       " 'out',\n",
       " 'take',\n",
       " 'one',\n",
       " 'up',\n",
       " 'me',\n",
       " 'make',\n",
       " 'than',\n",
       " 'should',\n",
       " 'now',\n",
       " 'so',\n",
       " 'president',\n",
       " 'think',\n",
       " 'who',\n",
       " 'your',\n",
       " 'or',\n",
       " 'today',\n",
       " 'can',\n",
       " 'there']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweet_tokenizer(s):\n",
    "    s = re.sub(r'#(\\S+)', r'HASHTAG_\\1', s)\n",
    "    s = re.sub(r'@(\\S+)', r'MENTION_\\1', s)\n",
    "    s = re.sub(r'http\\S+', 'THIS_IS_A_URL', s)\n",
    "    return re.sub('\\W+', ' ', s.lower()).split()\n",
    "\n",
    "def counters(d):\n",
    "    counts = Counter()  # handy object: dict from object -> int\n",
    "    counts.update(d)\n",
    "    return counts\n",
    "\n",
    "tokens = [token for tweet in df['text'] for token in tweet_tokenizer(tweet)]\n",
    "counts = counters(tokens)\n",
    "words_to_track = [i[0] for i in counts.most_common(70)]\n",
    "words_to_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    vec = DictVectorizer()\n",
    "    feature_dicts = []\n",
    "    # just as an initial example, we will consider three\n",
    "    # word features in the model.\n",
    "    words_to_track = ['think', 'today', 'should']\n",
    "    for i, row in df.iterrows():\n",
    "        features = {}\n",
    "        token_counts = Counter(re.sub('\\W+', ' ', row['text'].lower()).split())\n",
    "        for w in words_to_track:\n",
    "            features[w] = token_counts[w]\n",
    "        feature_dicts.append(features)\n",
    "    X = vec.fit_transform(feature_dicts)\n",
    "    return X, vec\n",
    "                \n",
    "X, vec = make_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are dimensions of the feature matrix?\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'think': 1, 'today': 2, 'should': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the feature names?\n",
    "# vocabulary_ is a dict from feature name to column index\n",
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          think\t43\n",
      "          today\t41\n",
      "         should\t44\n"
     ]
    }
   ],
   "source": [
    "# how often does each word occur?\n",
    "for word, idx in vec.vocabulary_.items():\n",
    "    print('%15s\\t%d' % (word, X[:,idx].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['should', 'think', 'today']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also get a simple list of feature names:\n",
    "vec.get_feature_names()\n",
    "# e.g., first column is 'hate', second is 'love', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-2.0: 650, -1.0: 176, 0.0: 201, 1.0: 89, 2.0: 141})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll first store the classes separately in a numpy array\n",
    "y = np.array(df.label)\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 826,  827,  828,  829,  830,  831,  832,  833,  834,  835,  836,\n",
       "        837,  838,  839,  840,  841,  842,  843,  844,  845,  846,  847,\n",
       "        848,  849,  850,  851,  852,  853,  854,  855,  856,  857,  858,\n",
       "        859,  860,  861,  862,  863,  864,  865,  866,  867,  868,  869,\n",
       "        870,  871,  872,  873,  874,  875,  876,  877,  878,  879,  880,\n",
       "        881,  882,  884,  885,  886,  887,  888,  889,  890,  891,  892,\n",
       "        893,  894,  895,  896,  897,  898,  899,  900,  901,  902,  903,\n",
       "        904,  905,  906,  907,  908,  909,  910,  911,  912,  913,  914,\n",
       "        915,  916,  917,  918,  919,  920,  921,  922,  923,  924,  925,\n",
       "        926,  927,  928,  929,  930,  931,  932,  933,  934,  935,  936,\n",
       "        937,  938,  939,  940,  941,  942,  943,  944,  945,  946,  947,\n",
       "        948,  949,  950,  951,  952,  953,  954,  955,  956,  957,  958,\n",
       "        959,  960,  961,  962,  963,  964,  965,  966,  967,  968,  969,\n",
       "        970,  971,  972,  973,  974,  975,  976,  977,  978,  979,  980,\n",
       "        981,  982,  983,  984,  985,  986,  987,  988,  989,  990,  991,\n",
       "        992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1002,\n",
       "       1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013,\n",
       "       1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024,\n",
       "       1025, 1026, 1027], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the row indices with hostile label\n",
    "np.where(y==0.0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the class names\n",
    "class_names = set(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               think\t                 0.0\t6\n",
      "               think\t                 1.0\t0\n",
      "               think\t                 2.0\t7\n",
      "               think\t                -1.0\t8\n",
      "               think\t                -2.0\t22\n",
      "               today\t                 0.0\t4\n",
      "               today\t                 1.0\t2\n",
      "               today\t                 2.0\t1\n",
      "               today\t                -1.0\t8\n",
      "               today\t                -2.0\t26\n",
      "              should\t                 0.0\t7\n",
      "              should\t                 1.0\t3\n",
      "              should\t                 2.0\t6\n",
      "              should\t                -1.0\t8\n",
      "              should\t                -2.0\t20\n"
     ]
    }
   ],
   "source": [
    "# how often does each word appear in each class?\n",
    "for word, idx in vec.vocabulary_.items():\n",
    "    for class_name in class_names:\n",
    "        class_idx = np.where(y==class_name)[0]\n",
    "        print('%20s\\t%20s\\t%d' % (word, class_name, X[class_idx, idx].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, `you` appears more frequently in positive (hostile) class, and `love` appears more frequently in the negative (non-hostile) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a LogisticRegression classifier.\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16441574,  0.13729807,  0.45481963],\n",
       "       [ 0.19063046,  0.38394791,  0.54849697],\n",
       "       [-0.05914492,  0.01068498, -0.19520814],\n",
       "       [-0.0681355 , -0.97844635, -0.08179174],\n",
       "       [ 0.1010657 ,  0.4465154 , -0.72631671]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for binary classification, LogisticRegression stores a single coefficient vector\n",
    "clf.coef_\n",
    "# this would be a matrix for a multi-class probem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16441574  0.13729807  0.45481963]\n",
      " [ 0.19063046  0.38394791  0.54849697]\n",
      " [-0.05914492  0.01068498 -0.19520814]\n",
      " [-0.0681355  -0.97844635 -0.08179174]\n",
      " [ 0.1010657   0.4465154  -0.72631671]]\n"
     ]
    }
   ],
   "source": [
    "# for binary classification, the coefficients for the negative class is just the negative of the positive class.\n",
    "coef = clf.coef_\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients for -2.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>should</th>\n",
       "      <th>think</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.164416</td>\n",
       "      <td>0.137298</td>\n",
       "      <td>0.45482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     should     think    today\n",
       "0 -0.164416  0.137298  0.45482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients for -1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>should</th>\n",
       "      <th>think</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19063</td>\n",
       "      <td>0.383948</td>\n",
       "      <td>0.548497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    should     think     today\n",
       "0  0.19063  0.383948  0.548497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients for 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>should</th>\n",
       "      <th>think</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.059145</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>-0.195208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     should     think     today\n",
       "0 -0.059145  0.010685 -0.195208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients for 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>should</th>\n",
       "      <th>think</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.068136</td>\n",
       "      <td>-0.978446</td>\n",
       "      <td>-0.081792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     should     think     today\n",
       "0 -0.068136 -0.978446 -0.081792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients for 2.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>should</th>\n",
       "      <th>think</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101066</td>\n",
       "      <td>0.446515</td>\n",
       "      <td>-0.726317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     should     think     today\n",
       "0  0.101066  0.446515 -0.726317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ci, class_name in enumerate(clf.classes_):\n",
    "    print('coefficients for %s' % class_name)\n",
    "    display(pd.DataFrame([coef[ci]], columns=vec.get_feature_names()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
