{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See instructions here:\n",
    "\n",
    "https://github.com/tapilab/elevate-osna-starter/blob/master/lessons/week2/README.md#day-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>timepercomm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972425520</td>\n",
       "      <td>true</td>\n",
       "      <td>rt @senjohnmccain : obama ha more czar than th...</td>\n",
       "      <td>7</td>\n",
       "      <td>78173527</td>\n",
       "      <td>11167646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2554608773</td>\n",
       "      <td>false</td>\n",
       "      <td>rt @thatkevinsmith : ten year in and we bone l...</td>\n",
       "      <td>87</td>\n",
       "      <td>1384707</td>\n",
       "      <td>15916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10288400197</td>\n",
       "      <td>true</td>\n",
       "      <td>rt @jimdemint : house appropriation chair davi...</td>\n",
       "      <td>13</td>\n",
       "      <td>63956</td>\n",
       "      <td>4919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15561382074</td>\n",
       "      <td>false</td>\n",
       "      <td>rt @markos : i get one for politifactref - - i...</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16415781807</td>\n",
       "      <td>unknown</td>\n",
       "      <td>rt @presssec : who would the gop put in charge...</td>\n",
       "      <td>84</td>\n",
       "      <td>3116561</td>\n",
       "      <td>37101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    label                                               text  \\\n",
       "0   1972425520     true  rt @senjohnmccain : obama ha more czar than th...   \n",
       "1   2554608773    false  rt @thatkevinsmith : ten year in and we bone l...   \n",
       "2  10288400197     true  rt @jimdemint : house appropriation chair davi...   \n",
       "3  15561382074    false  rt @markos : i get one for politifactref - - i...   \n",
       "4  16415781807  unknown  rt @presssec : who would the gop put in charge...   \n",
       "\n",
       "   comments_count  timeslot  timepercomm  \n",
       "0               7  78173527     11167646  \n",
       "1              87   1384707        15916  \n",
       "2              13     63956         4919  \n",
       "3               2        73           36  \n",
       "4              84   3116561        37101  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(datafile, checkfile):\n",
    "    \"\"\"\n",
    "    Read your data into a single pandas dataframe where\n",
    "    - each row is an instance to be classified\n",
    "    \n",
    "    (this could be a tweet, user, or news article, depending on your project)\n",
    "    - there is a column called `label` which stores the class label (e.g., the true\n",
    "      category for this row)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(datafile)[['social_id','comment_tokens','comment_time']]\n",
    "    ck = pd.read_csv(checkfile)\n",
    "    \n",
    "    ck = ck.loc[ck['site'] == 'twitter', ['site', 'social_id', 'ruling_val']]\n",
    "    \n",
    "    \n",
    "    ck['social_id'] = ck['social_id'].astype(df['social_id'].dtype)\n",
    "    \n",
    "    df.columns = ['id', 'text','time']\n",
    "#     df = df.drop_duplicates(['id','text'])\n",
    "    ck.columns = ['site','id','label']\n",
    "    df = pd.merge(ck,df,on=['id'],how = 'inner')\n",
    "    df['label'] = ['true' if i>0 else 'false' if i<0 else 'unknown' for i in df.label]\n",
    "    df['comments_count'] = 1\n",
    "    df['timemin'] = df['time']\n",
    "    \n",
    "    # combine multiple rows of an id into one row\n",
    "    def ab(df):\n",
    "        return' '.join(df.values)\n",
    "    df = df.groupby(['id','label']).agg({'text':ab,'comments_count':sum,'time':max,'timemin':min})\n",
    "    df['timeslot'] = df['time']-df['timemin']\n",
    "    df['timepercomm'] = df['timeslot']/df['comments_count']\n",
    "    df['timepercomm'] = [int(i) for i in df.timepercomm]\n",
    "    df = df.drop(['time','timemin'],axis=1)\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_data('..\\\\..\\\\training_data\\\\twitter.csv', '..\\\\..\\\\training_data\\\\factchecks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false      793\n",
       "true       224\n",
       "unknown    197\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution over class labels?\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    vec = DictVectorizer()\n",
    "    feature_dicts = []\n",
    "    # just as an initial example, we will consider three\n",
    "    # word features in the model.\n",
    "    words_to_track = ['you', 'hate', 'love']\n",
    "    # will get different model for different features.\n",
    "    for i, row in df.iterrows():\n",
    "        features = {}\n",
    "        token_counts = Counter(re.sub('\\W+', ' ', row['text'].lower()).split())\n",
    "        for w in words_to_track:\n",
    "            features[w] = token_counts[w]\n",
    "        feature_dicts.append(features)\n",
    "    X = vec.fit_transform(feature_dicts)\n",
    "    return X, vec\n",
    "                \n",
    "X, vec = make_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1214x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 101 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1214, 5519)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, use CountVectorizer to create a term feature matrix.\n",
    "count_vec = CountVectorizer()\n",
    "X_words = count_vec.fit_transform(df.text)\n",
    "X_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5519 words\n",
      "21101 of 6700066 possible cells are non-zero (0.31%)\n"
     ]
    }
   ],
   "source": [
    "# how sparse is it? \n",
    "def print_sparsity(X_words):\n",
    "    print('%d words' % X_words.shape[1])\n",
    "    num_cells = X_words.shape[0] * X_words.shape[1]\n",
    "    print('%d of %d possible cells are non-zero (%.2f%%)' %\n",
    "          (X_words.nnz, num_cells,\n",
    "           100 * X_words.nnz/num_cells))\n",
    "print_sparsity(X_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_df=1\n",
      "5519 words\n",
      "21101 of 6700066 possible cells are non-zero (0.31%)\n",
      "\n",
      "\n",
      "min_df=2\n",
      "1953 words\n",
      "17535 of 2370942 possible cells are non-zero (0.74%)\n",
      "\n",
      "\n",
      "min_df=5\n",
      "653 words\n",
      "14198 of 792742 possible cells are non-zero (1.79%)\n",
      "\n",
      "\n",
      "min_df=10\n",
      "289 words\n",
      "11850 of 350846 possible cells are non-zero (3.38%)\n"
     ]
    }
   ],
   "source": [
    "# how does sparsity vary with min_df?\n",
    "for min_df in [1,2,5,10]:\n",
    "    count_vec = CountVectorizer(min_df=min_df)\n",
    "    print('\\n\\nmin_df=%d' % min_df)\n",
    "    X_words = count_vec.fit_transform(df.text)\n",
    "    print_sparsity(X_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  rt\t69813\n",
      "                 the\t43717\n",
      "              urlref\t36591\n",
      "                  be\t35204\n",
      "                  to\t31350\n",
      "                  in\t20232\n",
      "                  of\t19614\n",
      "                 and\t15533\n",
      "     realdonaldtrump\t14273\n",
      "                 for\t10573\n"
     ]
    }
   ],
   "source": [
    "# top terms?\n",
    "def print_top_words(X_words, count_vec, n=10):\n",
    "    features = count_vec.get_feature_names()\n",
    "    word_counts = X_words.sum(axis=0).A1\n",
    "    for i in np.argsort(word_counts)[::-1][:n]:\n",
    "        print('%20s\\t%d' % (features[i], word_counts[i]))\n",
    "\n",
    "print_top_words(X_words, count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ngram_range=(1, 1)\n",
      "1953 words\n",
      "17535 of 2370942 possible cells are non-zero (0.74%)\n",
      "                  rt\t69813\n",
      "                 the\t43717\n",
      "              urlref\t36591\n",
      "                  be\t35204\n",
      "                  to\t31350\n",
      "                  in\t20232\n",
      "                  of\t19614\n",
      "                 and\t15533\n",
      "     realdonaldtrump\t14273\n",
      "                 for\t10573\n",
      "\n",
      "ngram_range=(2, 2)\n",
      "1814 words\n",
      "6224 of 2202196 possible cells are non-zero (0.28%)\n",
      "           urlref rt\t30885\n",
      "  rt realdonaldtrump\t11569\n",
      "              of the\t3610\n",
      "       urlref urlref\t2826\n",
      "              in the\t2775\n",
      "             this be\t2591\n",
      "              to the\t2540\n",
      "              on the\t2158\n",
      "               to be\t1986\n",
      "              be the\t1745\n",
      "\n",
      "ngram_range=(3, 3)\n",
      "516 words\n",
      "1304 of 626424 possible cells are non-zero (0.21%)\n",
      "    urlref urlref rt\t2771\n",
      "urlref rt realdonaldtrump\t1358\n",
      "urlref rt hillaryclinton\t1023\n",
      "rt realdonaldtrump the\t949\n",
      "     today urlref rt\t587\n",
      "         there be no\t492\n",
      "          one of the\t479\n",
      "      this urlref rt\t474\n",
      "        in the world\t461\n",
      "     the unite state\t427\n",
      "\n",
      "ngram_range=(1, 3)\n",
      "4283 words\n",
      "25063 of 5199562 possible cells are non-zero (0.48%)\n",
      "                  rt\t69813\n",
      "                 the\t43717\n",
      "              urlref\t36591\n",
      "                  be\t35204\n",
      "                  to\t31350\n",
      "           urlref rt\t30885\n",
      "                  in\t20232\n",
      "                  of\t19614\n",
      "                 and\t15533\n",
      "     realdonaldtrump\t14273\n"
     ]
    }
   ],
   "source": [
    "# top terms using different ngrams\n",
    "for ngram in [(1,1), (2,2), (3,3), (1,3)]:\n",
    "    count_vec = CountVectorizer(min_df=2, ngram_range=ngram)\n",
    "    print('\\nngram_range=%s' % str(ngram))\n",
    "    X_words = count_vec.fit_transform(df.text)\n",
    "    print_sparsity(X_words)\n",
    "    print_top_words(X_words, count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'false': 793, 'true': 224, 'unknown': 197})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll first store the classes separately in a numpy array\n",
    "y = np.array(df.label)\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the class names\n",
    "class_names = set(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 you\t               false\t3616\n",
      "                 you\t             unknown\t1352\n",
      "                 you\t                true\t1341\n",
      "                hate\t               false\t352\n",
      "                hate\t             unknown\t0\n",
      "                hate\t                true\t87\n",
      "                love\t               false\t500\n",
      "                love\t             unknown\t0\n",
      "                love\t                true\t85\n"
     ]
    }
   ],
   "source": [
    "# how often does each word appear in each class?\n",
    "for word, idx in list(vec.vocabulary_.items())[:10]:\n",
    "    for class_name in class_names:\n",
    "        class_idx = np.where(y==class_name)[0]\n",
    "        print('%20s\\t%20s\\t%d' % (word, class_name, X[class_idx, idx].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to combine two sparse matrices:\n",
    "from scipy.sparse import csr_matrix, hstack # \"horizontal stack\"\n",
    "# m1 = csr_matrix([[1,2,3], [4,5,6]])\n",
    "# print('m1')\n",
    "# print(m1.todense())\n",
    "# m2 = csr_matrix([[7,8], [9,10]])\n",
    "# print('m2')\n",
    "# print(m2.todense())\n",
    "# hstack([m1, m2]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1214, 4286)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = hstack([X, X_words])\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a LogisticRegression classifier.\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03080239,  0.06097997, -0.01932483, ..., -0.00907405,\n",
       "         0.02402858,  0.02402858],\n",
       "       [ 0.00434927,  0.01893742,  0.02934549, ..., -0.02399279,\n",
       "        -0.01215877, -0.01215877],\n",
       "       [-0.03515166, -0.07991739, -0.01002066, ...,  0.03306685,\n",
       "        -0.01186981, -0.01186981]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for binary classification, LogisticRegression stores a single coefficient vector\n",
    "clf.coef_\n",
    "# this would be a matrix for a multi-class probem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4286)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03080239  0.06097997 -0.01932483 ... -0.00907405  0.02402858\n",
      "   0.02402858]\n",
      " [ 0.00434927  0.01893742  0.02934549 ... -0.02399279 -0.01215877\n",
      "  -0.01215877]\n",
      " [-0.03515166 -0.07991739 -0.01002066 ...  0.03306685 -0.01186981\n",
      "  -0.01186981]]\n"
     ]
    }
   ],
   "source": [
    "# for binary classification, the coefficients for the negative class is just the negative of the positive class.\n",
    "coef = clf.coef_\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['false', 'true', 'unknown'], dtype=object)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all cross-validation folds: [0.6337448559670782, 0.6748971193415638, 0.6296296296296297, 0.6584362139917695, 0.6570247933884298]\n",
      "mean=0.65 std=0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train, test in kf.split(X):\n",
    "    clf.fit(X[train], y[train])\n",
    "    pred = clf.predict(X[test])\n",
    "    accuracies.append(accuracy_score(y[test], pred))\n",
    "    \n",
    "    \n",
    "print('accuracy over all cross-validation folds: %s' % str(accuracies))\n",
    "print('mean=%.2f std=%.2f' % (np.mean(accuracies), np.std(accuracies)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
