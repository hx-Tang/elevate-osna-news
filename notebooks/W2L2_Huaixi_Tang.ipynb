{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See instructions here:\n",
    "\n",
    "https://github.com/tapilab/elevate-osna-starter/blob/master/lessons/week2/README.md#day-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>timepercomm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972425520</td>\n",
       "      <td>true</td>\n",
       "      <td>rt @senjohnmccain : obama ha more czar than th...</td>\n",
       "      <td>7</td>\n",
       "      <td>78173527</td>\n",
       "      <td>11167646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2554608773</td>\n",
       "      <td>false</td>\n",
       "      <td>rt @thatkevinsmith : ten year in and we bone l...</td>\n",
       "      <td>87</td>\n",
       "      <td>1384707</td>\n",
       "      <td>15916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10288400197</td>\n",
       "      <td>true</td>\n",
       "      <td>rt @jimdemint : house appropriation chair davi...</td>\n",
       "      <td>13</td>\n",
       "      <td>63956</td>\n",
       "      <td>4919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15561382074</td>\n",
       "      <td>false</td>\n",
       "      <td>rt @markos : i get one for politifactref - - i...</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16415781807</td>\n",
       "      <td>unknown</td>\n",
       "      <td>rt @presssec : who would the gop put in charge...</td>\n",
       "      <td>84</td>\n",
       "      <td>3116561</td>\n",
       "      <td>37101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    label                                               text  \\\n",
       "0   1972425520     true  rt @senjohnmccain : obama ha more czar than th...   \n",
       "1   2554608773    false  rt @thatkevinsmith : ten year in and we bone l...   \n",
       "2  10288400197     true  rt @jimdemint : house appropriation chair davi...   \n",
       "3  15561382074    false  rt @markos : i get one for politifactref - - i...   \n",
       "4  16415781807  unknown  rt @presssec : who would the gop put in charge...   \n",
       "\n",
       "   comments_count  timeslot  timepercomm  \n",
       "0               7  78173527     11167646  \n",
       "1              87   1384707        15916  \n",
       "2              13     63956         4919  \n",
       "3               2        73           36  \n",
       "4              84   3116561        37101  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(datafile, checkfile):\n",
    "    \"\"\"\n",
    "    Read your data into a single pandas dataframe where\n",
    "    - each row is an instance to be classified\n",
    "    \n",
    "    (this could be a tweet, user, or news article, depending on your project)\n",
    "    - there is a column called `label` which stores the class label (e.g., the true\n",
    "      category for this row)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(datafile)[['social_id','comment_tokens','comment_time']]\n",
    "    ck = pd.read_csv(checkfile)\n",
    "    \n",
    "    ck = ck.loc[ck['site'] == 'twitter', ['site', 'social_id', 'ruling_val']]\n",
    "    \n",
    "    \n",
    "    ck['social_id'] = ck['social_id'].astype(df['social_id'].dtype)\n",
    "    \n",
    "    df.columns = ['id', 'text','time']\n",
    "#     df = df.drop_duplicates(['id','text'])\n",
    "    ck.columns = ['site','id','label']\n",
    "    df = pd.merge(ck,df,on=['id'],how = 'inner')\n",
    "    df['label'] = ['true' if i>0 else 'false' if i<0 else 'unknown' for i in df.label]\n",
    "    df['comments_count'] = 1\n",
    "    df['timemin'] = df['time']\n",
    "    \n",
    "    # combine multiple rows of an id into one row\n",
    "    def ab(df):\n",
    "        return' '.join(df.values)\n",
    "    df = df.groupby(['id','label']).agg({'text':ab,'comments_count':sum,'time':max,'timemin':min})\n",
    "    df['timeslot'] = df['time']-df['timemin']\n",
    "    df['timepercomm'] = df['timeslot']/df['comments_count']\n",
    "    df['timepercomm'] = [int(i) for i in df.timepercomm]\n",
    "    df = df.drop(['time','timemin'],axis=1)\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_data('..\\\\..\\\\training_data\\\\twitter.csv', '..\\\\..\\\\training_data\\\\factchecks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false      793\n",
       "true       224\n",
       "unknown    197\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution over class labels?\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    vec = DictVectorizer()\n",
    "    feature_dicts = []\n",
    "    # just as an initial example, we will consider three\n",
    "    # word features in the model.\n",
    "    words_to_track = ['you', 'hate', 'love']\n",
    "    # will get different model for different features.\n",
    "    for i, row in df.iterrows():\n",
    "        features = {}\n",
    "        token_counts = Counter(re.sub('\\W+', ' ', row['text'].lower()).split())\n",
    "        for w in words_to_track:\n",
    "            features[w] = token_counts[w]\n",
    "        feature_dicts.append(features)\n",
    "    X = vec.fit_transform(feature_dicts)\n",
    "    return X, vec\n",
    "                \n",
    "X, vec = make_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1214x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 101 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1214, 5519)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, use CountVectorizer to create a term feature matrix.\n",
    "# count_vec = CountVectorizer()\n",
    "# X_words = count_vec.fit_transform(df.text)\n",
    "# X_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how sparse is it? \n",
    "def print_sparsity(X_words):\n",
    "    print('%d words' % X_words.shape[1])\n",
    "    num_cells = X_words.shape[0] * X_words.shape[1]\n",
    "    print('%d of %d possible cells are non-zero (%.2f%%)' %\n",
    "          (X_words.nnz, num_cells,\n",
    "           100 * X_words.nnz/num_cells))\n",
    "# print_sparsity(X_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_df=1\n",
      "5519 words\n",
      "21101 of 6700066 possible cells are non-zero (0.31%)\n",
      "\n",
      "\n",
      "min_df=2\n",
      "1953 words\n",
      "17535 of 2370942 possible cells are non-zero (0.74%)\n",
      "\n",
      "\n",
      "min_df=5\n",
      "653 words\n",
      "14198 of 792742 possible cells are non-zero (1.79%)\n",
      "\n",
      "\n",
      "min_df=10\n",
      "289 words\n",
      "11850 of 350846 possible cells are non-zero (3.38%)\n"
     ]
    }
   ],
   "source": [
    "# how does sparsity vary with min_df?\n",
    "for min_df in [1,2,5,10]:\n",
    "    count_vec = CountVectorizer(min_df=min_df)\n",
    "    print('\\n\\nmin_df=%d' % min_df)\n",
    "    X_words = count_vec.fit_transform(df.text)\n",
    "    print_sparsity(X_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top terms?\n",
    "def print_top_words(X_words, count_vec, n=10):\n",
    "    features = count_vec.get_feature_names()\n",
    "    word_counts = X_words.sum(axis=0).A1\n",
    "    for i in np.argsort(word_counts)[::-1][:n]:\n",
    "        print('%20s\\t%d' % (features[i], word_counts[i]))\n",
    "\n",
    "# print_top_words(X_words, count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\=(1, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-cb9dc787a906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mfit_and_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mngram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-cb9dc787a906>\u001b[0m in \u001b[0;36mfit_and_predict\u001b[1;34m(min_df, max_df, ngram_range)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcount_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\=%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mX_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint_sparsity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint_top_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    884\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_doc_count\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 886\u001b[1;33m                     \"max_df corresponds to < documents than min_df\")\n\u001b[0m\u001b[0;32m    887\u001b[0m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0;32m    888\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# top terms using different ngrams\n",
    "def fit_and_predict(min_df=2.0, max_df=1.0, ngram_range=(1,1)):\n",
    "    count_vec = CountVectorizer(min_df=2, max_df=1, ngram_range=(1,1))\n",
    "    print('\\=%s' % str(ngram))\n",
    "    X_words = count_vec.fit_transform(df.text)\n",
    "    print_sparsity(X_words)\n",
    "    print_top_words(X_words, count_vec)\n",
    "    \n",
    "    y = np.array(df.label)\n",
    "\n",
    "    class_names = set(df.label)\n",
    "    \n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "#     X_all = hstack([X, X_words])\n",
    "    X_all = X_words\n",
    "    clf = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "    clf.fit(X_all, y)\n",
    "    \n",
    "    coef = clf.coef_\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    for train, test in kf.split(X_all):\n",
    "        clf.fit(X_all[train], y[train])\n",
    "        pred = clf.predict(X_all[test])\n",
    "        accuracies.append(accuracy_score(y[test], pred))\n",
    "\n",
    "\n",
    "    print('accuracy over all cross-validation folds: %s' % str(accuracies))\n",
    "    print('mean=%.2f std=%.2f' % (np.mean(accuracies), np.std(accuracies)))\n",
    "\n",
    "for ngram in [(1,1), (2,2), (3,3), (1,3)]:\n",
    "    fit_and_predict(ngram_range=ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'false': 793, 'true': 224, 'unknown': 197})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll first store the classes separately in a numpy array\n",
    "y = np.array(df.label)\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the class names\n",
    "class_names = set(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often does each word appear in each class?\n",
    "# for word, idx in list(vec.vocabulary_.items())[:10]:\n",
    "#     for class_name in class_names:\n",
    "#         class_idx = np.where(y==class_name)[0]\n",
    "#         print('%20s\\t%20s\\t%d' % (word, class_name, X[class_idx, idx].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to combine two sparse matrices:\n",
    "from scipy.sparse import csr_matrix, hstack # \"horizontal stack\"\n",
    "# m1 = csr_matrix([[1,2,3], [4,5,6]])\n",
    "# print('m1')\n",
    "# print(m1.todense())\n",
    "# m2 = csr_matrix([[7,8], [9,10]])\n",
    "# print('m2')\n",
    "# print(m2.todense())\n",
    "# hstack([m1, m2]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = hstack([X, X_words])\n",
    "X_all.shape\n",
    "# X_all = X_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a LogisticRegression classifier.\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07953326, -0.0132968 , -0.03093894, ..., -0.00630561,\n",
       "         0.02287026,  0.02287026],\n",
       "       [ 0.04056652,  0.02974951,  0.04463372, ..., -0.02042553,\n",
       "        -0.01176631, -0.01176631],\n",
       "       [-0.12009979, -0.01645271, -0.01369478, ...,  0.02673114,\n",
       "        -0.01110395, -0.01110395]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for binary classification, LogisticRegression stores a single coefficient vector\n",
    "clf.coef_\n",
    "# this would be a matrix for a multi-class probem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4283)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07953326 -0.0132968  -0.03093894 ... -0.00630561  0.02287026\n",
      "   0.02287026]\n",
      " [ 0.04056652  0.02974951  0.04463372 ... -0.02042553 -0.01176631\n",
      "  -0.01176631]\n",
      " [-0.12009979 -0.01645271 -0.01369478 ...  0.02673114 -0.01110395\n",
      "  -0.01110395]]\n"
     ]
    }
   ],
   "source": [
    "# for binary classification, the coefficients for the negative class is just the negative of the positive class.\n",
    "coef = clf.coef_\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['false', 'true', 'unknown'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all cross-validation folds: [0.6337448559670782, 0.654320987654321, 0.6008230452674898, 0.6172839506172839, 0.6033057851239669]\n",
      "mean=0.62 std=0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train, test in kf.split(X_all):\n",
    "    clf.fit(X_all[train], y[train])\n",
    "    pred = clf.predict(X_all[test])\n",
    "    accuracies.append(accuracy_score(y[test], pred))\n",
    "    \n",
    "    \n",
    "print('accuracy over all cross-validation folds: %s' % str(accuracies))\n",
    "print('mean=%.2f std=%.2f' % (np.mean(accuracies), np.std(accuracies)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
